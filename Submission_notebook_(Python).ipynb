{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Submission notebook (Python)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rdundas/hello-world/blob/master/Submission_notebook_(Python).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWq4q0Gfp1Ha"
      },
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <img alt=\"AIcrowd\" src=\"https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/master/pricing-game-banner.png\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIBNi6PiHFfD"
      },
      "source": [
        "# How to use this notebook üìù\n",
        "\n",
        "1. **Copy the notebook**. This is a shared template and any edits you make here will not be saved. _You should copy it into your own drive folder._ For this, click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You can edit your copy however you like.\n",
        "2. **Link it to your AICrowd account**. In order to submit your code to AICrowd, you need to provide your account's API key (see [_\"Configure static variables\"_](#static-var) for details).\n",
        "3. **Stick to the function definitions**. The submission to AICrowd will look for the pre-defined function names:\n",
        "  - `fit_model`\n",
        "  - `save_model`\n",
        "  - `load_model`\n",
        "  - `predict_expected_claim`\n",
        "  - `predict_premium`\n",
        "\n",
        "    Anything else you write outside of these functions will not be part of the final submission (including constants and utility functions), so make sure everything is defined within them, except for:\n",
        "4. **Define your preprocessing**. In addition to the functions above, anything in the cell labelled [_\"Define your data preprocessing\"_](#data-preprocessing) will also be imported into your final submission. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uor1bk8ud9Yf"
      },
      "source": [
        "# Your pricing model üïµÔ∏è\n",
        "\n",
        "In this notebook, you can play with the data, and define and train your pricing model. You can then directly submit it to the AICrowd, with some magic code at the end.\n",
        "\n",
        "### Baseline logistic regression üí™\n",
        "You can also play with a baseline logistic regression model [implemented here](https://colab.research.google.com/drive/1iDgDgWUw9QzOkbTYjeyY3i3DGuCoghs3?usp=sharing). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOG9aspEPfLo"
      },
      "source": [
        "# Setup the notebook üõ†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc9aD_S9w_Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fd1783-8386-4e86-a987-3947b8e51c97"
      },
      "source": [
        "!bash <(curl -sL https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/master/python/setup.sh)\n",
        "from aicrowd_helpers import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚öôÔ∏è Installing AIcrowd utilities...\n",
            "  Running command git clone -q https://gitlab.aicrowd.com/yoogottamk/aicrowd-cli /tmp/pip-req-build-9sz0mn1x\n",
            "‚úÖ Installed AIcrowd utilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWAkvr2mPqhO"
      },
      "source": [
        "# Configure static variables üìé\n",
        "<a name=\"static-var\"></a>\n",
        "\n",
        "In order to submit using this notebook, you must visit this URL https://aicrowd.com/participants/me and copy your API key. \n",
        "\n",
        "Then you must set the value of `AICROWD_API_KEY` wuth the value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8nmleFd9Yf"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "class Config:\n",
        "  TRAINING_DATA_PATH = 'training.csv'\n",
        "  MODEL_OUTPUT_PATH = 'model.pkl'\n",
        "  AICROWD_API_KEY = '230b234f3c90fb788f439d7f1e13c1bb'  # You can get the key from https://aicrowd.com/participants/me\n",
        "  ADDITIONAL_PACKAGES = [\n",
        "    'numpy',  # you can define versions as well, numpy==0.19.2\n",
        "    'pandas',\n",
        "    'scikit-learn==' + sklearn.__version__,\n",
        "    # NOTE THAT ANY TENSORFLOW VERSION HAS TO BE LOWER THAN 2.4. So 2.3XXX would work. \n",
        "  ]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK8Ki2WUjVoX"
      },
      "source": [
        "# Download dataset files üíæ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgKzpAV0jVFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021d3dd5-6882-4c38-c5ae-a74e35c965e3"
      },
      "source": [
        "# Make sure to offically join the challenge and accept the challenge rules! Otherwise you will not be able to download the data\n",
        "%download_aicrowd_dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üíæ Downloading dataset...\n",
            "Verifying API Key...\n",
            "API Key valid\n",
            "Saved API Key successfully!\n",
            "‚úÖ Downloaded dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wrBpC0qd9Yg"
      },
      "source": [
        "# Packages üóÉ\n",
        "\n",
        "<a name=\"packages\"></a>\n",
        "\n",
        "Import here all the packages you need to define your model. **You will need to include all of these packages in `Config.ADDITIONAL_PACKAGES` for your code to run properly once submitted.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4C50Fsd9Yg"
      },
      "source": [
        "%%track_imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR62QOUGd9Yg"
      },
      "source": [
        "import importlib\n",
        "import global_imports\n",
        "importlib.reload(global_imports)\n",
        "from global_imports import *  # do not change this"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRgsbwWwd9Yg"
      },
      "source": [
        "# Loading the data üì≤"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQghMU7d9Yg"
      },
      "source": [
        "df = pd.read_csv(Config.TRAINING_DATA_PATH)\n",
        "X_train = df.drop(columns=['claim_amount'])\n",
        "y_train = df['claim_amount']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WArx8uDQd9Yh"
      },
      "source": [
        "## How does the data look like? üîç"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_dyebPyQbSO"
      },
      "source": [
        "#X_train.sample(n=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoJEQhxMQtq9"
      },
      "source": [
        "#y_train.sample(n=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynDfq7F_d9Yh"
      },
      "source": [
        "# Training the model üöÄ\n",
        "\n",
        "You must first define your first function: `fit_model`. This function takes training data as arguments, and outputs a \"model\" object -- that you define as you wish. For instance, this could be an array of parameter values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpW0yH_Lj2hG"
      },
      "source": [
        "## Define your data preprocessing\n",
        "\n",
        "<a name=\"data-preprocessing\"></a>\n",
        "\n",
        "You can add any class or function in this cell for preprocessing. Just make sure that you use the functions here in the `fit_model`, `predict_expected_claim` and `predict_premium` functions if necessary. *italicised text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buq4-7IIjsUq"
      },
      "source": [
        "%%aicrowd_include\n",
        "# This magical command saves all code in this cell to a utils module.\n",
        "\n",
        "# include your preprocessing functions and classes here. "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtL2L7SgFg0c"
      },
      "source": [
        "import importlib\n",
        "import utils\n",
        "importlib.reload(utils)\n",
        "from utils import *  # do not change this"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zShvukipOXZP"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAaNQuVxRTUs"
      },
      "source": [
        "## Define the training logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffOanSIvd9Yh"
      },
      "source": [
        "def fit_model(X_raw, y_raw):\n",
        "    \"\"\"Model training function: given training data (X_raw, y_raw), train this pricing model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
        "        Each row is a different contract. This data has not been processed.\n",
        "    y_raw : a Numpy array, with the value of the claims, in the same order as contracts in X_raw.\n",
        "        A one dimensional array, with values either 0 (most entries) or >0.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self: this instance of the fitted model. This can be anything, as long as it is compatible\n",
        "        with your prediction methods.\n",
        "\n",
        "    \"\"\"\n",
        "    X_raw['claim_amount']=y_raw\n",
        "\n",
        "    #CORRECT FOR NA VALUES\n",
        "\n",
        "    #set age and license values to be zero\n",
        "    X_raw['drv_age2']=X_raw['drv_age2'].fillna(0)\n",
        "    X_raw['drv_age_lic2']=X_raw['drv_age_lic2'].fillna(0)\n",
        "    #remove nas in make model\n",
        "    mask = X_raw['vh_age'].isna()\n",
        "    X_raw.loc[mask, 'vh_age'] = X_raw[X_raw['vh_make_model']=='coufviypetbrtevy']['vh_age'].mean()\n",
        "    #correct for other nas\n",
        "    for makes in set(X_raw[X_raw['vh_weight'].isna()|X_raw['vh_value'].isna()|X_raw['vh_speed'].isna()]['vh_make_model']):\n",
        "    \n",
        "      mask = X_raw['vh_speed'].isna()\n",
        "      X_raw.loc[mask, 'vh_speed'] = X_raw['vh_speed'].mean()\n",
        "    \n",
        "      mask = X_raw['vh_value'].isna()\n",
        "      X_raw.loc[mask, 'vh_value'] = X_raw['vh_value'].mean()\n",
        "\n",
        "      mask = X_raw['vh_weight'].isna()\n",
        "      X_raw.loc[mask, 'vh_weight'] = X_raw['vh_weight'].mean()\n",
        "\n",
        "    #NOW DO CLAIM MANIPULATION\n",
        "\n",
        "    X_raw['has_claim']=(X_raw['claim_amount']>0).astype(int)\n",
        "    #Cap large claims\n",
        "    X_raw['claim_amount_capped']=X_raw['claim_amount'].apply(lambda x : min(x,5000))\n",
        "\n",
        "    #get number of previous claims and total previous claim amounts\n",
        "    prev_claims=X_raw[[\"id_policy\",\"year\",\"claim_amount_capped\",'has_claim']].sort_values(by=['id_policy','year'])\n",
        "    prev_claims['all_claims']=prev_claims.groupby([\"id_policy\"])[\"has_claim\"].cumsum()\n",
        "    prev_claims['all_claims_amts']=prev_claims.groupby([\"id_policy\"])[\"claim_amount_capped\"].cumsum()\n",
        "    prev_claims['prev_claims']=prev_claims['all_claims']-prev_claims['has_claim']\n",
        "    prev_claims['prev_claims_amts']=prev_claims['all_claims_amts']-prev_claims['claim_amount_capped']\n",
        "    prev_claims.drop([\"claim_amount_capped\",'has_claim','all_claims','all_claims_amts'],axis=1,inplace=True)\n",
        "    #join onto main df\n",
        "    X_raw=X_raw.merge(prev_claims,how='left',on=[\"id_policy\",\"year\"])\n",
        "\n",
        "    #if data not there then set to zero\n",
        "    X_raw['prev_claims']=X_raw['prev_claims'].fillna(0)\n",
        "    X_raw['prev_claims_amts']=X_raw['prev_claims_amts'].fillna(0)\n",
        "\n",
        "    #Now do categorical features\n",
        "    #now look at make and model, need to bin as too larger\n",
        "    make_model=X_raw[['vh_make_model','has_claim','claim_amount_capped','prev_claims','prev_claims_amts']].groupby('vh_make_model').agg(('count','mean'))\n",
        "    make_model.columns\n",
        "    make_model=make_model.sort_values([('has_claim','count')],ascending=False)\n",
        "\n",
        "    keep_models=make_model.index[0:50].tolist()\n",
        "    mask=~X_raw['vh_make_model'].isin(keep_models)\n",
        "    X_raw.loc[mask, 'vh_make_model'] = 'Other'\n",
        "\n",
        "    enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "    enc.fit(df[['pol_coverage','pol_pay_freq','pol_payd','pol_usage','drv_sex1','drv_drv2','drv_sex2','vh_fuel','vh_type','vh_make_model']])\n",
        "    \n",
        "    cat_vars=pd.DataFrame(enc.transform(X_raw[['pol_coverage','pol_pay_freq','pol_payd','pol_usage','drv_sex1','drv_drv2','drv_sex2','vh_fuel','vh_type','vh_make_model']]))\n",
        "    cat_vars.columns=enc.get_feature_names(['pol_coverage','pol_pay_freq','pol_payd','pol_usage','drv_sex1','drv_drv2','drv_sex2','vh_fuel','vh_type','vh_make_model'])\n",
        "    \n",
        "    X_raw=pd.concat([X_raw,cat_vars],axis=1)\n",
        "    X_raw.drop(['pol_coverage','pol_pay_freq','pol_payd','pol_usage','drv_sex1','drv_drv2','drv_sex2','vh_fuel','vh_type','vh_make_model'],axis=1,inplace=True)\n",
        "    # TODO: train your model here.\n",
        "    # Don't forget any preprocessing of the raw data here\n",
        "    \n",
        "    #now train models\n",
        "    X_freq=df.drop(['has_claim','claim_amount','id_policy','claim_amount_capped'],axis=1)\n",
        "    y_freq=df['has_claim']\n",
        "    X_sev=df[df['has_claim']==1].drop(['has_claim','claim_amount','id_policy','claim_amount_capped'],axis=1)\n",
        "    y_sev=df[df['has_claim']==1]['claim_amount_capped']\n",
        "\n",
        "    return np.mean(y_raw)  # By default, training a model that returns a mean value (a mean model)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOfWQpbYtES"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfjGFHcXd9Yh"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wtCLn_Xd9Yi"
      },
      "source": [
        "trained_model = fit_model(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjUk7tfjd9Yi"
      },
      "source": [
        "**Important note**: your training code should be able to run in under 10 minutes (since this notebook is re-run entirely on the server side). \n",
        "\n",
        "If you run into an issue here we recommend using the *zip file submission* (see the [challenge page](https://www.aicrowd.com/challenges/insurance-pricing-game/#how-to%20submit)). In short, you can simply do this by copy-pasting your `fit_model`, `predict_expected_claim` and `predict_premium` functions to the `model.py` file.\n",
        "\n",
        "Note that if you want to perform extensive cross-validation/hyper-parameter selection, it is better to do them offline, in a separate notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWYcr_Ued9Yi"
      },
      "source": [
        "## Saving your model\n",
        "\n",
        "You can save your model to a file here, so you don't need to retrain it every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6iWwkmHd9Yi"
      },
      "source": [
        "def save_model(model_path):  # some models such xgboost models or keras models don't pickle very reliably. Please use the package provided saving functions instead. \n",
        "  with open(model_path, 'wb') as target_file:\n",
        "      pickle.dump(trained_model, target_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwEEP95EMow4"
      },
      "source": [
        "save_model(Config.MODEL_OUTPUT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G3KPnlsd9Yi"
      },
      "source": [
        "If you need to load it from file, you can use this code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICY88PT5d9Yi"
      },
      "source": [
        "def load_model(model_path): # some models such xgboost models or keras models don't pickle very reliably. Please use the package provided saving functions instead. \n",
        "  with open(model_path, 'rb') as target:\n",
        "      return pickle.load(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxTX1TYOMsWK"
      },
      "source": [
        "trained_model = load_model(Config.MODEL_OUTPUT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVeJiR1Ud9Yi"
      },
      "source": [
        "# Predicting the claims üíµ\n",
        "\n",
        "The second function, `predict_expected_claim`, takes your trained model and a dataframe of contracts, and outputs a prediction for the (expected) claim incurred by each contract. This expected claim can be seen as the probability of an accident multiplied by the cost of that accident.\n",
        "\n",
        "This is the function used to compute the _RMSE_ leaderboard, where the model best able to predict claims wins."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgM1xNf0d9Yi"
      },
      "source": [
        "def predict_expected_claim(model, X_raw):\n",
        "    \"\"\"Model prediction function: predicts the expected claim based on the pricing model.\n",
        "\n",
        "    This functions estimates the expected claim made by a contract (typically, as the product\n",
        "    of the probability of having a claim multiplied by the expected cost of a claim if it occurs),\n",
        "    for each contract in the dataset X_raw.\n",
        "\n",
        "    This is the function used in the RMSE leaderboard, and hence the output should be as close\n",
        "    as possible to the expected cost of a contract.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: a Python object that describes your model. This can be anything, as long\n",
        "        as it is consistent with what `fit` outpurs.\n",
        "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
        "        Each row is a different contract. This data has not been processed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    avg_claims: a one-dimensional Numpy array of the same length as X_raw, with one\n",
        "        expected claim per contract (in same order). These expected claims must be POSITIVE (>0).\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: estimate the expected claim of every contract.\n",
        "    # Don't forget any preprocessing of the raw data here\n",
        "    \n",
        "    return np.full( (len(X_raw.index),), model )  # Estimate that each contract will cost 114 (this is the naive mean model). You should change this!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN7RqHcld9Yi"
      },
      "source": [
        "To test your function, run it on your training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Pu1UE-d9Yi"
      },
      "source": [
        "predict_expected_claim(trained_model, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LuitAiQd9Yi"
      },
      "source": [
        "# Pricing contracts üí∞üí∞\n",
        "\n",
        "The third and final function, `predict_premium`, takes your trained model and a dataframe of contracts, and outputs a _price_ for each of these contracts. **You are free to set this prices however you want!** These prices will then be used in competition with other models: contracts will choose the model offering the lowest price, and this model will have to pay the cost if an accident occurs.\n",
        "\n",
        "This is the function used to compute the _profit_ leaderboard: your model will participate in many markets of size 10, populated by other participants' model, and we compute the average profit of your model over all the markets it participated in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agmv13hnd9Yi"
      },
      "source": [
        "def predict_premium(model, X_raw):\n",
        "    \"\"\"Model prediction function: predicts premiums based on the pricing model.\n",
        "\n",
        "    This function outputs the prices that will be offered to the contracts in X_raw.\n",
        "    premium will typically depend on the average claim predicted in \n",
        "    predict_average_claim, and will add some pricing strategy on top.\n",
        "\n",
        "    This is the function used in the average profit leaderboard. Prices output here will\n",
        "    be used in competition with other models, so feel free to use a pricing strategy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: a Python object that describes your model. This can be anything, as long\n",
        "        as it is consistent with what `fit` outpurs.\n",
        "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
        "        Each row is a different contract. This data has not been processed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    prices: a one-dimensional Numpy array of the same length as X_raw, with one\n",
        "        price per contract (in same order). These prices must be POSITIVE (>0).\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: return a price for everyone.\n",
        "    # Don't forget any preprocessing of the raw data here\n",
        "\n",
        "    return predict_expected_claim(model, X_raw) * 2  # Default: bosst prices by a factor of 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu7T3lQ_d9Yi"
      },
      "source": [
        "To test your function, run it on your training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Ej-1zcd9Yi"
      },
      "source": [
        "prices = predict_premium(trained_model, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcU5hWPHd9Yi"
      },
      "source": [
        "#### Profit on training data\n",
        "\n",
        "In order for your model to be considered in the profit competition, it needs to make nonnegative profit over its training set. You can check that your model satisfies this condition below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf389fhYd9Yi"
      },
      "source": [
        "print('Income:', prices.sum())\n",
        "print('Losses:', y_train.sum())\n",
        "\n",
        "if prices.sum() < y_train.sum():\n",
        "    print('Your model loses money on the training data! It does not satisfy market rule 1: Non-negative training profit.')\n",
        "    print('This model will be disqualified from the weekly profit leaderboard, but can be submitted for educational purposes to the RMSE leaderboard.')\n",
        "else:\n",
        "    print('Your model passes the non-negative training profit test!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQlsVqDqd9Yi"
      },
      "source": [
        "# Ready? Submit to AIcrowd üöÄ\n",
        "\n",
        "If you are satisfied with your code, run the code below to send your code to the AICrowd servers for evaluation! This requires the variable `trained_model` to be defined by your previous code.\n",
        "\n",
        "**Make sure you have included all packages needed to run your code in the [_\"Packages\"_](#packages) section.**\n",
        "\n",
        "**NOTE**: If you submit the baseline RMSE model without any change whatsoever, your model will not be entered into the market. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovm0PyTEd9Yi"
      },
      "source": [
        "%aicrowd_submit"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}